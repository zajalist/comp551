{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9da7b17",
   "metadata": {},
   "source": [
    "# Phase A: The MLE Approach\n",
    "\n",
    "Here, we use the MLE approach to detect the likelihood of getting a word in a spam or ham message using [the SMS spam dataset collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection).\n",
    "\n",
    "## Limitations\n",
    "Vocabulary Bias: By using .split(), every unique string is treated (including punctuation attached to words like \"win!\") as a unique feature.\n",
    "\n",
    "Bag-of-Words Assumption: This model assumes that the order of words doesn't matter, only their frequency.\n",
    "\n",
    "Zero-multiplier: If a sentence containing many spam words has a single word which is not in our dataset of spam words, because\n",
    "we multiply probabilities, it will render the probability of the whole message \"0\", even though the presence of multiple spam words\n",
    "makes it very likely that it is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42fdffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# Get the path relative to the notebook location\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "data_path = os.path.join('..', 'data', 'sms_spam', 'SMSSpamCollection')\n",
    "\n",
    "# Load the training data\n",
    "df = pd.read_csv(data_path, sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "# Separate spam and ham messages\n",
    "spam_messages = df[df['label'] == 'spam']['message']\n",
    "ham_messages = df[df['label'] == 'ham']['message']\n",
    "\n",
    "# Count word occurrences per category\n",
    "def count_words_by_category(messages):\n",
    "    word_counts = defaultdict(int)\n",
    "    for message in messages:\n",
    "        words = message.lower().split()\n",
    "        for word in words:\n",
    "            word_counts[word] += 1\n",
    "    return word_counts\n",
    "\n",
    "spam_word_counts = count_words_by_category(spam_messages)\n",
    "ham_word_counts = count_words_by_category(ham_messages)\n",
    "\n",
    "# Calculate theta_word for each category\n",
    "total_spam_words = sum(spam_word_counts.values())\n",
    "total_ham_words = sum(ham_word_counts.values())\n",
    "\n",
    "theta_spam = {word: count / total_spam_words for word, count in spam_word_counts.items()}\n",
    "theta_ham = {word: count / total_ham_words for word, count in ham_word_counts.items()}\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "top_ham = sorted(theta_ham.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "top_spam = sorted(theta_spam.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "print(f\"Top {top_n} ham words:\")\n",
    "for word, prob in top_ham:\n",
    "    print(f\"{word}: {prob:.6f}\")\n",
    "\n",
    "print(f\"\\nTop {top_n} spam words:\")\n",
    "for word, prob in top_spam:\n",
    "    print(f\"{word}: {prob:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a619cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
